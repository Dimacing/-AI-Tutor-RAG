# Архитектура

## Обзор
MVP представляет собой RAG-сервис с индексатором и пользовательским интерфейсом.
Бэкенд предоставляет эндпоинт `/query`, который извлекает релевантные чанки из индекса
и вызывает LLM для генерации ответа с цитированием источников.

## Высокоуровневый поток
```
+-----------+     +-----------+     +-------------+     +------------+
| Источники | --> | Ingest    | --> | Эмбеддинги  | --> | Индекс     |
+-----------+     +-----------+     +-------------+     +------------+
                                                        |
                                                        v
+-----------+     +-----------+     +-------------+     +------------+
| UI        | --> | /query    | --> | Retrieve    | --> | Ответ LLM  |
+-----------+     +-----------+     +-------------+     +------------+
```

## Компоненты
- `backend.rag.ingest`: загрузка источников (URL или локальные файлы), извлечение текста, чанкинг
- `backend.rag.index`: построение эмбеддингов и запись `data/index`
- `backend.rag.retrieve`: поиск по косинусному сходству вектора
- `backend.rag.prompt`: формирование промпта с контекстом источников
- `backend.rag.llm`: клиенты OpenAI, Gemini, DeepSeek, Ollama, GigaChat
- `backend.main`: FastAPI-эндпоинты, безопасность, логирование
- `web/`: кастомный веб-UI
- `ui/streamlit_app.py`: Streamlit UI
- `backend.telegram_bot.py`: Telegram-бот

## Поток данных
1) Источники собираются в `data/sources.json`.
2) `python -m backend.rag.index` строит `chunks.json` и векторный индекс Qdrant в `data/index/qdrant`.
3) `/query` эмбеддит вопрос, извлекает топ чанки и вызывает LLM.
4) Ответ включает текст, цитаты, самопроверку и рекомендации.
